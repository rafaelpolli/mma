{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e17f0-42be-488e-ad53-dfb29826694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, List\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "#from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "import lxml\n",
    "import json\n",
    "import getpass\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import Dict, Optional\n",
    "import os\n",
    "\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "import chromadb\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "from typing import List, Optional\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "WORKING_DIRECTORY = Path(os.environ[\"WORKING_DIRECTORY\"])\n",
    "\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"should be a search query\")\n",
    "\n",
    "@tool\n",
    "def search_on_web(question: Annotated[str, \"The user question to be searced in the index.\"],\n",
    "                   page_num = 0, page_limit=10, language=\"en\", country=\"br\",\n",
    "                    headers={\"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36\"}):\n",
    "    \n",
    "    \"\"\"Use this to search the internet to gete more information about any question. The information might be wrong\"\"\"\n",
    "    \n",
    "    params = {\n",
    "    \"q\" : question + ' do ItaÃº Unibanco',\n",
    "    \"h1\" : language,\n",
    "    \"g1\" : country,\n",
    "    \"start\" : 0\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    while True:\n",
    "        page_num += 1\n",
    "        \n",
    "        khtml = requests.get(\"http://www.google.com/search\",\n",
    "                            params=params, headers = headers, timeout=30)\n",
    "        soup = BeautifulSoup(khtml.text, 'lxml')\n",
    "        \n",
    "        for result in soup.select(\".tF2Cxc\"):\n",
    "            title = result.select_one(\".DKV0Md\").text\n",
    "            try:\n",
    "                snippet = result.select_one(\".lEBKkf span\").text\n",
    "            except:\n",
    "                snippet = None\n",
    "            links = result.select_one(\".yuRUbf a\")[\"href\"]\n",
    "            \n",
    "            data.append({\n",
    "            \"title\": title,\n",
    "            \"snippet\": snippet,\n",
    "            \"links\": links\n",
    "            })\n",
    "            \n",
    "            \n",
    "        if page_num == page_limit:\n",
    "            break\n",
    "        if soup.select_one(\".d6cvqb a[id=pnnext]\"):\n",
    "            params[\"start\"] += 10\n",
    "        else:\n",
    "            break\n",
    "    \n",
    "    return json.dumps(data, indent=2, ensure_ascii=False)\n",
    "\n",
    "def vector_store_init(persist_directory: str = \"data\",\n",
    "                        collection_name: str = \"gdp\",\n",
    "                        doc: str = \"content.txt\",\n",
    "                     append: bool = False):\n",
    "    \n",
    "    os.environ[\"PERSIST_DIRECTORY\"] = persist_directory\n",
    "    os.environ[\"COLLECTION_NAME\"] = collection_name\n",
    "    \n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    # Load the Chroma database from disk\n",
    "    chroma_db = Chroma(persist_directory=persist_directory, \n",
    "                       embedding_function=embeddings,\n",
    "                       collection_name=collection_name)\n",
    "    \n",
    "    # Get the collection from the Chroma database\n",
    "    collection = chroma_db.get(collection_name)\n",
    "    \n",
    "    with open(doc) as f:\n",
    "        content = f.read()\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    pages = text_splitter.split_text(content)\n",
    "    \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = text_splitter.create_documents(pages)\n",
    "    \n",
    "    # If the collection is empty, create a new one\n",
    "    if append:\n",
    "        # Create a new Chroma database from the documents\n",
    "        chroma_db = Chroma.from_documents(\n",
    "            documents=docs, \n",
    "            embedding=embeddings, \n",
    "            persist_directory=persist_directory,\n",
    "            collection_name=collection_name\n",
    "        )\n",
    "    \n",
    "        # Save the Chroma database to disk\n",
    "        chroma_db.persist()\n",
    "    return chroma_db\n",
    "\n",
    "# Define the custom search tool\n",
    "@tool(\"search-tool\", args_schema=SearchInput, return_direct=False)\n",
    "def chromadb_search(query: str) -> list:\n",
    "    \"\"\"\n",
    "    Perform a search in the ChromaDB collection using OpenAI embeddings.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of search results.\n",
    "    \"\"\"\n",
    "    # Initialize your embedding function\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "  \n",
    "    # Load the Chroma database from disk\n",
    "    chroma_db = Chroma(persist_directory=os.environ[\"PERSIST_DIRECTORY\"], embedding_function=embeddings, collection_name = os.environ[\"COLLECTION_NAME\"])\n",
    "    # Convert the query to an embedding using the OpenAIEmbeddings instance\n",
    "    \n",
    "    # Perform the search using embeddings within the specified collection\n",
    "    results = chroma_db.similarity_search(query, k = 4)\n",
    "\n",
    "    # Process and return the results\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def create_outline(\n",
    "    points: Annotated[List[str], \"List of main points or sections.\"],\n",
    "    file_name: Annotated[str, \"File path to save the outline.\"],\n",
    ") -> Annotated[str, \"Path of the saved outline file.\"]:\n",
    "    \"\"\"Create and save an outline.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        for i, point in enumerate(points):\n",
    "            file.write(f\"{i + 1}. {point}\\n\")\n",
    "    return f\"Outline saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_document(\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    "    start: Annotated[Optional[int], \"The start line. Default is 0\"] = None,\n",
    "    end: Annotated[Optional[int], \"The end line. Default is None\"] = None,\n",
    ") -> str:\n",
    "    \"\"\"Read the specified document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "    if start is not None:\n",
    "        start = 0\n",
    "    return \"\\n\".join(lines[start:end])\n",
    "\n",
    "\n",
    "@tool\n",
    "def write_document(\n",
    "    content: Annotated[str, \"Text content to be written into the document.\"],\n",
    "    file_name: Annotated[str, \"File path to save the document.\"],\n",
    ") -> Annotated[str, \"Path of the saved document file.\"]:\n",
    "    \"\"\"Create and save a text document.\"\"\"\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.write(content)\n",
    "    return f\"Document saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def edit_document(\n",
    "    file_name: Annotated[str, \"Path of the document to be edited.\"],\n",
    "    inserts: Annotated[\n",
    "        Dict[int, str],\n",
    "        \"Dictionary where key is the line number (1-indexed) and value is the text to be inserted at that line.\",\n",
    "    ],\n",
    ") -> Annotated[str, \"Path of the edited document file.\"]:\n",
    "    \"\"\"Edit a document by inserting text at specific line numbers.\"\"\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"r\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    sorted_inserts = sorted(inserts.items())\n",
    "\n",
    "    for line_number, text in sorted_inserts:\n",
    "        if 1 <= line_number <= len(lines) + 1:\n",
    "            lines.insert(line_number - 1, text + \"\\n\")\n",
    "        else:\n",
    "            return f\"Error: Line number {line_number} is out of range.\"\n",
    "\n",
    "    with (WORKING_DIRECTORY / file_name).open(\"w\") as file:\n",
    "        file.writelines(lines)\n",
    "\n",
    "    return f\"Document edited and saved to {file_name}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    return f\"Successfully executed:\\n```python\\n{code}\\n```\\nStdout: {result}\"\n",
    "\n",
    "def create_agent(\n",
    "    llm: ChatOpenAI,\n",
    "    tools: list,\n",
    "    system_prompt: str,\n",
    ") -> str:\n",
    "    \"\"\"Create a function-calling agent and add it to the graph.\"\"\"\n",
    "    system_prompt += \"\\nWork autonomously according to your specialty, using the tools available to you.\"\n",
    "    \" Do not ask for clarification.\"\n",
    "    \" Your other team members (and other teams) will collaborate with you with their own specialties.\"\n",
    "    \" You are chosen for a reason! You are one of the following team members: {team_members}.\"\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                system_prompt,\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_functions_agent(llm, tools, prompt)\n",
    "    executor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return executor\n",
    "\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}\n",
    "\n",
    "\n",
    "def create_team_supervisor(llm: ChatOpenAI, system_prompt, members) -> str:\n",
    "    \"\"\"An LLM-based router.\"\"\"\n",
    "    options = [\"FINISH\"] + members\n",
    "    function_def = {\n",
    "        \"name\": \"route\",\n",
    "        \"description\": \"Select the next role.\",\n",
    "        \"parameters\": {\n",
    "            \"title\": \"routeSchema\",\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"next\": {\n",
    "                    \"title\": \"Next\",\n",
    "                    \"anyOf\": [\n",
    "                        {\"enum\": options},\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"next\"],\n",
    "        },\n",
    "    }\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Given the conversation above, who should act next?\"\n",
    "                \" Or should we FINISH? Select one of: {options}\",\n",
    "            ),\n",
    "        ]\n",
    "    ).partial(options=str(options), team_members=\", \".join(members))\n",
    "    return (\n",
    "        prompt\n",
    "        | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "        | JsonOutputFunctionsParser()\n",
    "    )\n",
    "\n",
    "\n",
    "import operator\n",
    "from pathlib import Path\n",
    "from hma.utils import *\n",
    "import functools\n",
    "\n",
    "\n",
    "WORKING_DIRECTORY = Path(os.environ[\"WORKING_DIRECTORY\"])\n",
    "\n",
    "\n",
    "class Writer():\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=os.environ[\"MODEL\"])\n",
    "        \n",
    "        self.doc_writer_agent = create_agent(\n",
    "            self.llm,\n",
    "            [write_document, edit_document, read_document],\n",
    "            \"You are an expert writing a customer service script. All content you write must be based on information brought on the message. Don't makeup information, if you don't have enought information to write about, return 'Need more context'\\n\"\n",
    "            # The {current_files} value is populated automatically by the graph state\n",
    "            \"Below are files currently in your directory:\\n{current_files}\",\n",
    "        )\n",
    "        \n",
    "        self.context_aware_doc_writer_agent = prelude | self.doc_writer_agent\n",
    "        self.doc_writing_node = functools.partial(\n",
    "            agent_node, agent=self.context_aware_doc_writer_agent, name=\"DocWriter\"\n",
    "        )\n",
    "        \n",
    "        self.note_taking_agent = create_agent(\n",
    "            self.llm,\n",
    "            [create_outline, read_document],\n",
    "            \"You are an expert senior expert tasked with writing a customer service script outline and\"\n",
    "            \" taking notes to craft a perfect customer service script. All content you write must be based on information brought on the message. Don't makeup information, if you don't have enought information to write about, return 'Need more context'{current_files}\",\n",
    "        )\n",
    "        \n",
    "        self.context_aware_note_taking_agent = prelude | self.note_taking_agent\n",
    "        self.note_taking_node = functools.partial(\n",
    "            agent_node, agent=self.context_aware_note_taking_agent, name=\"NoteTaker\"\n",
    "        )\n",
    "        \n",
    "        \n",
    "#        self.chart_generating_agent = create_agent(\n",
    "#            self.llm,\n",
    "#            [read_document, python_repl],\n",
    "#            \"You are a data viz expert tasked with generating charts for a research project.\"\n",
    "#            \"{current_files}\",\n",
    "#        )\n",
    "        \n",
    "#        self.context_aware_chart_generating_agent = prelude | self.chart_generating_agent\n",
    "#        self.chart_generating_node = functools.partial(\n",
    "#            agent_node, agent=self.context_aware_note_taking_agent, name=\"ChartGenerator\"\n",
    "#        )\n",
    "        \n",
    "        self.doc_writing_supervisor = create_team_supervisor(\n",
    "            self.llm,\n",
    "            \"You are a supervisor tasked with managing a conversation between the\"\n",
    "            \" following workers:  {team_members}. Given the following user request,\"\n",
    "            \" respond with the worker to act next. Each worker will perform a\"\n",
    "            \" task and respond with their results and status. When finished,\"\n",
    "            \" respond with FINISH.\",\n",
    "            [\"DocWriter\", \"NoteTaker\"#, \"ChartGenerator\"\n",
    "            ],\n",
    "        )\n",
    "        \n",
    "        # Create the graph here:\n",
    "        # Note that we have unrolled the loop for the sake of this doc\n",
    "        self.authoring_graph = StateGraph(DocWritingState)\n",
    "        self.authoring_graph.add_node(\"DocWriter\", self.doc_writing_node)\n",
    "        self.authoring_graph.add_node(\"NoteTaker\", self.note_taking_node)\n",
    "#        self.authoring_graph.add_node(\"ChartGenerator\", self.chart_generating_node)\n",
    "        self.authoring_graph.add_node(\"supervisor\", self.doc_writing_supervisor)\n",
    "        \n",
    "        # Add the edges that always occur\n",
    "        self.authoring_graph.add_edge(\"DocWriter\", \"supervisor\")\n",
    "        self.authoring_graph.add_edge(\"NoteTaker\", \"supervisor\")\n",
    "#        self.authoring_graph.add_edge(\"ChartGenerator\", \"supervisor\")\n",
    "        \n",
    "        # Add the edges where routing applies\n",
    "        self.authoring_graph.add_conditional_edges(\n",
    "            \"supervisor\",\n",
    "            lambda x: x[\"next\"],\n",
    "            {\n",
    "                \"DocWriter\": \"DocWriter\",\n",
    "                \"NoteTaker\": \"NoteTaker\",\n",
    "#                \"ChartGenerator\": \"ChartGenerator\",\n",
    "                \"FINISH\": END,\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        self.authoring_graph.add_edge(START, \"supervisor\")\n",
    "        self.chain = self.authoring_graph.compile()\n",
    "        \n",
    "        # We reuse the enter/exit functions to wrap the graph\n",
    "        self.authoring_chain = (\n",
    "            functools.partial(enter_chain, members=self.authoring_graph.nodes)\n",
    "            | self.authoring_graph.compile()\n",
    "        )\n",
    "        \n",
    "\n",
    "# The following functions interoperate between the top level graph state\n",
    "# and the state of the research sub-graph\n",
    "# this makes it so that the states of each graph don't get intermixed\n",
    "def enter_chain(message: str, members: List[str]):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "        \"team_members\": \", \".join(members),\n",
    "    }\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "# This will be run before each worker agent begins work\n",
    "# It makes it so they are more aware of the current state\n",
    "# of the working directory.\n",
    "def prelude(state):\n",
    "    written_files = []\n",
    "    if not WORKING_DIRECTORY.exists():\n",
    "        WORKING_DIRECTORY.mkdir()\n",
    "    try:\n",
    "        written_files = [\n",
    "            f.relative_to(WORKING_DIRECTORY) for f in WORKING_DIRECTORY.rglob(\"*\")\n",
    "        ]\n",
    "    except Exception:\n",
    "        pass\n",
    "    if not written_files:\n",
    "        return {**state, \"current_files\": \"No files written.\"}\n",
    "    return {\n",
    "        **state,\n",
    "        \"current_files\": \"\\nBelow are files your team has written to the directory:\\n\"\n",
    "        + \"\\n\".join([f\" - {f}\" for f in written_files]),\n",
    "    }\n",
    "\n",
    "# Document writing team graph state\n",
    "class DocWritingState(TypedDict):\n",
    "    # This tracks the team's conversation internally\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    # This provides each worker with context on the others' skill sets\n",
    "    team_members: str\n",
    "    # This is how the supervisor tells langgraph who to work next\n",
    "    next: str\n",
    "    # This tracks the shared directory state\n",
    "    current_files: str\n",
    "    \n",
    "    \n",
    "    \n",
    "from hma.utils import *\n",
    "import functools\n",
    "import operator\n",
    "\n",
    "\n",
    "\n",
    "class Search:    \n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=os.environ[\"MODEL\"])\n",
    "        \n",
    "        self.search_agent = create_agent(\n",
    "            self.llm,\n",
    "            [chromadb_search],\n",
    "            \"You are a research assistant who can search for up-to-date info using the chromadb_search engine tool, you must use the tool. Don't makeup information, if you don't have enought information to retrieve, return 'I am not able to find information about this topic'\",\n",
    "        )\n",
    "        \n",
    "        self.search_node = functools.partial(agent_node, agent=self.search_agent, name=\"Search\")\n",
    "\n",
    "        self.scrapper_agent = create_agent(\n",
    "            self.llm,\n",
    "            [search_on_web],\n",
    "            \"You are a research assistant who can search for up-to-date info using the chromadb_search engine tool, you must use the tool. Don't makeup information, if you don't have enought information to retrieve, return 'I am not able to find information about this topic'\",\n",
    "        )\n",
    "     \n",
    "        self.scrapper_node = functools.partial(agent_node, agent=self.scrapper_agent, name=\"WebScraper\")\n",
    "        \n",
    "        self.supervisor_agent = create_team_supervisor(\n",
    "            self.llm,\n",
    "            \"You are a supervisor tasked with managing a conversation between the\"\n",
    "            \" following workers:  Search, WebScraper. Given the following user request,\"\n",
    "            \" respond with the worker to act next. Each worker will perform a\"\n",
    "            \" task and respond with their results and status. When finished,\"\n",
    "            \" respond with FINISH.\",\n",
    "            [\"Search\", \"WebScraper\"],\n",
    "        )\n",
    "        \n",
    "        self.search_graph = StateGraph(SearchTeamState)\n",
    "        self.search_graph.add_node(\"Search\", self.search_node)\n",
    "        self.search_graph.add_node(\"WebScraper\", self.scrapper_node)\n",
    "        self.search_graph.add_node(\"supervisor\", self.supervisor_agent)\n",
    "        \n",
    "        # Define the control flow\n",
    "        self.search_graph.add_edge(\"Search\", \"supervisor\")\n",
    "        self.search_graph.add_edge(\"WebScraper\", \"supervisor\")\n",
    "        self.search_graph.add_conditional_edges(\n",
    "            \"supervisor\",\n",
    "            lambda x: x[\"next\"],\n",
    "            {\"Search\": \"Search\", \"WebScraper\": \"WebScraper\", \"FINISH\": END},\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.search_graph.add_edge(START, \"supervisor\")\n",
    "        self.chain = self.search_graph.compile()       \n",
    "        \n",
    "        self.search_chain = enter_chain | self.chain\n",
    "        \n",
    "# The following functions interoperate between the top level graph state\n",
    "# and the state of the research sub-graph\n",
    "# this makes it so that the states of each graph don't get intermixed\n",
    "def enter_chain(message: str):\n",
    "    results = {\n",
    "        \"messages\": [HumanMessage(content=message)],\n",
    "    }\n",
    "    return results\n",
    "        \n",
    "# ResearchTeam graph state\n",
    "class SearchTeamState(TypedDict):\n",
    "    # A message is added after each team member finishes\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    # The team members are tracked so they are aware of\n",
    "    # the others' skill-sets\n",
    "    team_members: List[str]\n",
    "    # Used to route work. The supervisor calls a function\n",
    "    # that will update this every time it makes a decision\n",
    "    next: str\n",
    "    \n",
    "    \n",
    "import operator\n",
    "from hma.utils import *\n",
    "import functools\n",
    "import hma.search as search\n",
    "import hma.writer as writer\n",
    "\n",
    "class Coordinator:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(model=os.environ[\"MODEL\"])\n",
    "        self.writer_team = writer.Writer()\n",
    "        self.search_team = search.Search()\n",
    "        \n",
    "        \n",
    "        self.coordinator_node = create_team_supervisor(\n",
    "            self.llm,\n",
    "            \"\"\"You are a coordinator tasked with managing a conversation between the\"\n",
    "             following teams: {team_members}. Given the following user request,\n",
    "             respond with the worker to act next. Each worker will perform a\n",
    "             task and respond with their results and status. When finished,\n",
    "             respond with FINISH.\"\"\",\n",
    "            [\"SearchTeam\", \"WritingTeam\"],\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Define the graph.\n",
    "        self.super_graph = StateGraph(State)\n",
    "        # First add the nodes, which will do the work\n",
    "        self.super_graph.add_node(\"SearchTeam\", get_last_message | self.search_team.search_chain | join_graph)\n",
    "        self.super_graph.add_node(\n",
    "            \"WritingTeam\", get_last_message | self.writer_team.authoring_chain | join_graph\n",
    "        )\n",
    "        self.super_graph.add_node(\"coordinator\", self.coordinator_node)\n",
    "        \n",
    "        # Define the graph connections, which controls how the logic\n",
    "        # propagates through the program\n",
    "        self.super_graph.add_edge(\"SearchTeam\", \"coordinator\")\n",
    "        self.super_graph.add_edge(\"WritingTeam\", \"coordinator\")\n",
    "        self.super_graph.add_conditional_edges(\n",
    "            \"coordinator\",\n",
    "            lambda x: x[\"next\"],\n",
    "            {\n",
    "                \"WritingTeam\": \"WritingTeam\",\n",
    "                \"SearchTeam\": \"SearchTeam\",\n",
    "                \"FINISH\": END,\n",
    "            },\n",
    "        )\n",
    "        self.super_graph.add_edge(START, \"coordinator\")\n",
    "        self.super_graph = self.super_graph.compile()\n",
    "        \n",
    "        \n",
    "        \n",
    "# Top-level graph state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    next: str\n",
    "\n",
    "\n",
    "def get_last_message(state: State) -> str:\n",
    "    return state[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "def join_graph(response: dict):\n",
    "    return {\"messages\": [response[\"messages\"][-1]]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded0dafd-7cd6-427c-823a-c915dfc24208",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-custom_python:Python",
   "language": "python",
   "name": "conda-env-.conda-custom_python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
